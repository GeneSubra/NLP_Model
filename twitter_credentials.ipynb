{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Capstone: Twitter Sentiment Alaysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An election for president of the United States happens every four years on the first Tuesday after the first Monday in November. Candidates are elected directly by popular vote.\n",
    "#### I performed some data exploration and visualization in this notebook using data from Twitter to gather the candidates popularity and the chances for them to win the race. This analysis also provides customer sentiment towards polical party and how to connect with voters.\n",
    "\n",
    "##### Data Source: Twitter\n",
    "\n",
    "#### The intended audience of this is any candidate that have decided to run for the election and wanted insights of himself and other candidates. This information can lead the candicate to invest their time and money where it is required.\n",
    "\n",
    "#### The notebook work flow is as follows:\n",
    "\n",
    "##### _ Framing the \n",
    "##### - Loading dataset to pandas dataframe\n",
    "##### - Data exploration and cleaning\n",
    "##### - Insights extraction\n",
    "##### - Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Twitter API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = \"2579829499-HkSx8z7ToV0rPouv27z4HwFRFIdJM0f57GUgdzv\"\n",
    "ACCESS_TOKEN_SECRET = \"w5LhkcI3FdlZaK7cKFOCR9hRXmqkCDWbl3uPJVAE6n1UL\"\n",
    "CONSUMER_KEY = \"kfYddvhVO6vRrn1yNG4N6C6iA\"\n",
    "CONSUMER_SECRET = \"Jlj9vj1M3PYJ3I1CVM9ZtYeuZxI1jS8DUWoTzFRY43mGimMWVi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Thinkful\\\\Assignments\\\\Module 44 Final Capstone\\\\Master'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from tweepy import API\n",
    "from tweepy import cursor\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "public_tweets = api.home_timeline()\n",
    "#for tweet in public_tweets:\n",
    "    #print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter AUthenticator\n",
    "class TwitterAuthenticator ():\n",
    "    def  authenticate_twitter_app(self):\n",
    "        auth = OAuthHandler(twitter_credentials.CONSUMER_KEY, twitter_credentials.CONSUMER_SECRET)\n",
    "        auth.set_access_token(twitter_credentials.ACCESS_TOKEN, twitter_credentials.ACCESS_TOKEN_SECRET)\n",
    "        return auth\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterStreamer():\n",
    "    \"\"\"\n",
    "    Class for streaming and processing live tweets.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.twitter_authenticator = TwitterAuthenticator()\n",
    "\n",
    "    def stream_tweets(self, fetched_tweets_filename, hash_tag_list):\n",
    "        # This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "        listener = TwittertListener(fetched_tweets_filename)\n",
    "        auth = self.twitter_authenticator.authenticate_twitter_app()\n",
    "        stream = Stream(auth, listener)\n",
    "\n",
    "        # This line filter Twitter Streams to capture data by the keywords: \n",
    "        stream.filter(track=hash_tag_list)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "# # # # TWITTER STREAM LISTENER # # # #\n",
    "class TwittertListener(StreamListener):\n",
    "    \"\"\"\n",
    "    This is a basic listener that just prints received tweets to stdout.\n",
    "    \"\"\"\n",
    "    def __init__(self, fetched_tweets_filename):\n",
    "        self.fetched_tweets_filename = fetched_tweets_filename\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            print(data)\n",
    "            with open(self.fetched_tweets_filename, 'a') as tf:\n",
    "                tf.write(data)\n",
    "            return True\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data %s\" % str(e))\n",
    "        return True\n",
    "          \n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide key word to gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    " \n",
    "    # Authenticate using config.py and connect to Twitter Streaming API.\n",
    "    hash_tag_list = [\"CelsiusOfficial\", '@CelsiusOfficial']\n",
    "    #fetched_tweets_filename = \"tweets.txt\"\n",
    "    fetched_tweets_filename = \"CelsiusOfficial_tweets.json\"\n",
    "\n",
    "    twitter_streamer = TwitterStreamer()\n",
    "    twitter_streamer.stream_tweets(fetched_tweets_filename, hash_tag_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from here and adjust the JSON file for smaller size Git Bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-65273f965981>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#df= pd.read_json(\"tweets_1.json\", encoding=\"utf8\", lines = True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CelsiusOfficial_tweets.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    713\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"frame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"series\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 849\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m             self.obj = DataFrame(\n\u001b[1;32m-> 1093\u001b[1;33m                 \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m             )\n\u001b[0;32m   1095\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"split\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "# create dataframe\n",
    "import pandas as pd\n",
    "#df= pd.read_json(\"tweets_1.json\", encoding=\"utf8\", lines = True)\n",
    "df= pd.read_json(\"CelsiusOfficial_tweets.json\", encoding=\"utf8\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Thinkful\\\\Assignments\\\\Module 44 Final Capstone\\\\Master'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mystring' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-9fc9184e6844>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'[⺀-⺙⺛-⻳⼀-⿕々〇〡-〩〸-〺〻㐀-䶵一-鿃豈-鶴侮-頻並-龎]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNICODE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmystring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mystring' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "df = re.compile(u'[⺀-⺙⺛-⻳⼀-⿕々〇〡-〩〸-〺〻㐀-䶵一-鿃豈-鶴侮-頻並-龎]', re.UNICODE)\n",
    "df = df.sub('', mystring, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>entities</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>filter_level</th>\n",
       "      <th>lang</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>extended_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-09 13:33:27+00:00</td>\n",
       "      <td>1226499350437584896</td>\n",
       "      <td>1226499350437584896</td>\n",
       "      <td>RT @TheMassiveMK: me and the boys after enteri...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-02-09 13:33:27.057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-09 13:33:27+00:00</td>\n",
       "      <td>1226499350882398208</td>\n",
       "      <td>1226499350882398208</td>\n",
       "      <td>RT @DrMattMcCarthy: Here's what isn't being sa...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [{'text': 'coronavirus', 'indices...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-02-09 13:33:27.163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-09 13:33:27+00:00</td>\n",
       "      <td>1226499351461187584</td>\n",
       "      <td>1226499351461187584</td>\n",
       "      <td>RT @DPCgov: #Coronavirus: continua l'impegno d...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [{'text': 'Coronavirus', 'indices...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>it</td>\n",
       "      <td>2020-02-09 13:33:27.301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-09 13:33:27+00:00</td>\n",
       "      <td>1226499352077705217</td>\n",
       "      <td>1226499352077705216</td>\n",
       "      <td>RT @RFY_cn: 【民愤？】\\n距苏媒消息，武汉封城已导致武汉群体愤怒 https:/...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>zh</td>\n",
       "      <td>2020-02-09 13:33:27.448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-09 13:33:27+00:00</td>\n",
       "      <td>1226499352891289600</td>\n",
       "      <td>1226499352891289600</td>\n",
       "      <td>RT @chrisjesulee: Coronavirus kills people in ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-02-09 13:33:27.642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at                   id               id_str  \\\n",
       "0 2020-02-09 13:33:27+00:00  1226499350437584896  1226499350437584896   \n",
       "1 2020-02-09 13:33:27+00:00  1226499350882398208  1226499350882398208   \n",
       "2 2020-02-09 13:33:27+00:00  1226499351461187584  1226499351461187584   \n",
       "3 2020-02-09 13:33:27+00:00  1226499352077705217  1226499352077705216   \n",
       "4 2020-02-09 13:33:27+00:00  1226499352891289600  1226499352891289600   \n",
       "\n",
       "                                                text  \\\n",
       "0  RT @TheMassiveMK: me and the boys after enteri...   \n",
       "1  RT @DrMattMcCarthy: Here's what isn't being sa...   \n",
       "2  RT @DPCgov: #Coronavirus: continua l'impegno d...   \n",
       "3  RT @RFY_cn: 【民愤？】\\n距苏媒消息，武汉封城已导致武汉群体愤怒 https:/...   \n",
       "4  RT @chrisjesulee: Coronavirus kills people in ...   \n",
       "\n",
       "                                              source  truncated  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "3  <a href=\"https://mobile.twitter.com\" rel=\"nofo...      False   \n",
       "4  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "0                    NaN                        NaN                  NaN   \n",
       "1                    NaN                        NaN                  NaN   \n",
       "2                    NaN                        NaN                  NaN   \n",
       "3                    NaN                        NaN                  NaN   \n",
       "4                    NaN                        NaN                  NaN   \n",
       "\n",
       "   in_reply_to_user_id_str  ...  \\\n",
       "0                      NaN  ...   \n",
       "1                      NaN  ...   \n",
       "2                      NaN  ...   \n",
       "3                      NaN  ...   \n",
       "4                      NaN  ...   \n",
       "\n",
       "                                            entities favorited  retweeted  \\\n",
       "0  {'hashtags': [], 'urls': [], 'user_mentions': ...     False      False   \n",
       "1  {'hashtags': [{'text': 'coronavirus', 'indices...     False      False   \n",
       "2  {'hashtags': [{'text': 'Coronavirus', 'indices...     False      False   \n",
       "3  {'hashtags': [], 'urls': [{'url': 'https://t.c...     False      False   \n",
       "4  {'hashtags': [], 'urls': [], 'user_mentions': ...     False      False   \n",
       "\n",
       "   filter_level lang            timestamp_ms possibly_sensitive  \\\n",
       "0           low   en 2020-02-09 13:33:27.057                NaN   \n",
       "1           low   en 2020-02-09 13:33:27.163                NaN   \n",
       "2           low   it 2020-02-09 13:33:27.301                NaN   \n",
       "3           low   zh 2020-02-09 13:33:27.448                0.0   \n",
       "4           low   en 2020-02-09 13:33:27.642                NaN   \n",
       "\n",
       "   extended_entities  display_text_range extended_tweet  \n",
       "0                NaN                 NaN            NaN  \n",
       "1                NaN                 NaN            NaN  \n",
       "2                NaN                 NaN            NaN  \n",
       "3                NaN                 NaN            NaN  \n",
       "4                NaN                 NaN            NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>entities</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>filter_level</th>\n",
       "      <th>lang</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>extended_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>2020-02-09 13:36:42+00:00</td>\n",
       "      <td>1226500170625376258</td>\n",
       "      <td>1226500170625376256</td>\n",
       "      <td>RT @BuzzFeedNews: People in China are using th...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-02-09 13:36:42.605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>2020-02-09 13:36:42+00:00</td>\n",
       "      <td>1226500170994585600</td>\n",
       "      <td>1226500170994585600</td>\n",
       "      <td>RT @BelpietroTweet: Giovedì ero ospite di Del ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>it</td>\n",
       "      <td>2020-02-09 13:36:42.693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>2020-02-09 13:36:42+00:00</td>\n",
       "      <td>1226500171187605504</td>\n",
       "      <td>1226500171187605504</td>\n",
       "      <td>RT @ESahresh: Right now he is only one who is ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [{'text': 'PakistaniStudents', 'i...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-02-09 13:36:42.739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>2020-02-09 13:36:42+00:00</td>\n",
       "      <td>1226500171510366208</td>\n",
       "      <td>1226500171510366208</td>\n",
       "      <td>RT @DrAmalinaBakri: @zurairi @KKMPutrajaya htt...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>und</td>\n",
       "      <td>2020-02-09 13:36:42.816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>2020-02-09 13:36:42+00:00</td>\n",
       "      <td>1226500171678339072</td>\n",
       "      <td>1226500171678339072</td>\n",
       "      <td>RT @Shubymo: I guess such assertions were base...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-02-09 13:36:42.856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    created_at                   id               id_str  \\\n",
       "2716 2020-02-09 13:36:42+00:00  1226500170625376258  1226500170625376256   \n",
       "2717 2020-02-09 13:36:42+00:00  1226500170994585600  1226500170994585600   \n",
       "2718 2020-02-09 13:36:42+00:00  1226500171187605504  1226500171187605504   \n",
       "2719 2020-02-09 13:36:42+00:00  1226500171510366208  1226500171510366208   \n",
       "2720 2020-02-09 13:36:42+00:00  1226500171678339072  1226500171678339072   \n",
       "\n",
       "                                                   text  \\\n",
       "2716  RT @BuzzFeedNews: People in China are using th...   \n",
       "2717  RT @BelpietroTweet: Giovedì ero ospite di Del ...   \n",
       "2718  RT @ESahresh: Right now he is only one who is ...   \n",
       "2719  RT @DrAmalinaBakri: @zurairi @KKMPutrajaya htt...   \n",
       "2720  RT @Shubymo: I guess such assertions were base...   \n",
       "\n",
       "                                                 source  truncated  \\\n",
       "2716  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "2717  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "2718  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "2719  <a href=\"https://mobile.twitter.com\" rel=\"nofo...      False   \n",
       "2720  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "\n",
       "      in_reply_to_status_id  in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "2716                    NaN                        NaN                  NaN   \n",
       "2717                    NaN                        NaN                  NaN   \n",
       "2718                    NaN                        NaN                  NaN   \n",
       "2719                    NaN                        NaN                  NaN   \n",
       "2720                    NaN                        NaN                  NaN   \n",
       "\n",
       "      in_reply_to_user_id_str  ...  \\\n",
       "2716                      NaN  ...   \n",
       "2717                      NaN  ...   \n",
       "2718                      NaN  ...   \n",
       "2719                      NaN  ...   \n",
       "2720                      NaN  ...   \n",
       "\n",
       "                                               entities favorited  retweeted  \\\n",
       "2716  {'hashtags': [], 'urls': [], 'user_mentions': ...     False      False   \n",
       "2717  {'hashtags': [], 'urls': [], 'user_mentions': ...     False      False   \n",
       "2718  {'hashtags': [{'text': 'PakistaniStudents', 'i...     False      False   \n",
       "2719  {'hashtags': [], 'urls': [{'url': 'https://t.c...     False      False   \n",
       "2720  {'hashtags': [], 'urls': [], 'user_mentions': ...     False      False   \n",
       "\n",
       "      filter_level lang            timestamp_ms possibly_sensitive  \\\n",
       "2716           low   en 2020-02-09 13:36:42.605                NaN   \n",
       "2717           low   it 2020-02-09 13:36:42.693                NaN   \n",
       "2718           low   en 2020-02-09 13:36:42.739                NaN   \n",
       "2719           low  und 2020-02-09 13:36:42.816                0.0   \n",
       "2720           low   en 2020-02-09 13:36:42.856                NaN   \n",
       "\n",
       "      extended_entities  display_text_range extended_tweet  \n",
       "2716                NaN                 NaN            NaN  \n",
       "2717                NaN                 NaN            NaN  \n",
       "2718                NaN                 NaN            NaN  \n",
       "2719                NaN                 NaN            NaN  \n",
       "2720                NaN                 NaN            NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data and model it\n",
    "\n",
    "# Removing punctuations\n",
    "df_wordclean = df.iloc[:,3:4]\n",
    "df_wordclean.replace(\"[^a-zA-Z]\",\" \",regex=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT  TheMassiveMK  me and the boys after enteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT  DrMattMcCarthy  Here s what isn t being sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT  DPCgov   Coronavirus  continua l impegno d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT  RFY cn                            https   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT  chrisjesulee  Coronavirus kills people in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  RT  TheMassiveMK  me and the boys after enteri...\n",
       "1  RT  DrMattMcCarthy  Here s what isn t being sa...\n",
       "2  RT  DPCgov   Coronavirus  continua l impegno d...\n",
       "3  RT  RFY cn                            https   ...\n",
       "4  RT  chrisjesulee  Coronavirus kills people in ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wordclean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wordclean[\"text\"]=df[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @themassivemk: me and the boys after enteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @drmattmccarthy: here's what isn't being sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @dpcgov: #coronavirus: continua l'impegno d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @rfy_cn: 【民愤？】\\n距苏媒消息，武汉封城已导致武汉群体愤怒 https:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @chrisjesulee: coronavirus kills people in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  rt @themassivemk: me and the boys after enteri...\n",
       "1  rt @drmattmccarthy: here's what isn't being sa...\n",
       "2  rt @dpcgov: #coronavirus: continua l'impegno d...\n",
       "3  rt @rfy_cn: 【民愤？】\\n距苏媒消息，武汉封城已导致武汉群体愤怒 https:/...\n",
       "4  rt @chrisjesulee: coronavirus kills people in ..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wordclean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to label and train\n",
    "# load from file and predict using the best configs found in the CV step\n",
    "\n",
    "model_NB = joblib.load(\"twitter_sentiment.pkl\" )\n",
    "\n",
    "# get predictions from best model above\n",
    "y_preds = model_NB.predict(df_wordclean['text'])\n",
    "score = model_NB.predict_proba(df_wordclean['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score\n",
    "#probability of label 0 & 1. inthis case it is 0.8/0.16= 0 (negative sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wordclean['predictions'] = y_preds.tolist()\n",
    "# to show the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wordclean['probability'] = score.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wordclean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wordclean[df_wordclean['predictions']==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_wordclean[df_wordclean['predictions']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_wordclean[df_wordclean['predictions']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_wordclean[df_wordclean['predictions']==-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wordclean['text'][1]\n",
    "# 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wordclean['text'][585]\n",
    "# 1-  negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wordclean['text'][577]\n",
    "# 1 - negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why the above is positive! Model not train on potty words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The modelling above is very confusing to understand. Need to clean up the text and remove filler words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob: textblob is the python library for processing textual data.\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_wordclean['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing to get the lat & long\n",
    "bboxes = []\n",
    "lats = []\n",
    "lons = []\n",
    "polarityArr = []\n",
    "messages = []\n",
    "for index,row in df.iterrows():\n",
    "    if(row.place is None):\n",
    "            continue\n",
    "    bbox = np.array(row.place['bounding_box']['coordinates'][0])\n",
    "    lat = bbox.mean(axis=0).tolist()[1]\n",
    "    lon = bbox.mean(axis=0).tolist()[0]\n",
    "    # to remove points outside US\n",
    " \n",
    "    if not (lat > 25.79 and  lat < 49.50 and lon > -129.73 and lon < -66.44):\n",
    "        continue\n",
    "    bboxes.append(bbox)\n",
    "    lats.append(lat)\n",
    "    lons.append(lon)\n",
    "    analysis = TextBlob((row['text']))\n",
    "    messages.append(row['text'])\n",
    "    polarity = analysis.sentiment.polarity\n",
    "    \n",
    "     # set sentiment \n",
    "    if analysis.sentiment.polarity > 0: \n",
    "            polarityArr.append('positive')\n",
    "    elif analysis.sentiment.polarity == 0: \n",
    "            polarityArr.append('neutral')\n",
    "    else: \n",
    "            polarityArr.append('negative')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(polarityArr)\n",
    "# if greater than zero, it is +ve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(messages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe with lat, lon & polarity\n",
    "d = {'text':messages, 'latitude':lats, 'longitude':lons, 'sentiment':polarityArr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df from this dict\n",
    "df_geomap = pd.DataFrame(d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geomap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import descartes\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_map = gpd.read_file('C:\\Thinkful\\Assignments\\Final_Project_2\\FullYoutubeVideo\\cb_2018_us_county_20m\\cb_2018_us_county_20m.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now need to create a geo pandas df\n",
    "geometry = [Point(xy) for xy in zip(df_geomap['longitude'],df_geomap['latitude'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping\n",
    "crs = {'init':'epsg:4326'}\n",
    "geo_df = gpd.GeoDataFrame(df_geomap, crs = crs, geometry = geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use shapely by US County\n",
    "fig,ax = plt.subplots(figsize = (20,20))\n",
    "street_map.plot(ax=ax, alpha=0.4, color ='gray')\n",
    "geo_df[geo_df['sentiment']=='positive'].plot(ax=ax, markersize = 20, color = \"blue\", marker =\"o\", label = \"Pos\")\n",
    "geo_df[geo_df['sentiment']=='negative'].plot(ax=ax, markersize = 20, color = \"red\", marker =\"o\", label = \"Neg\")\n",
    "geo_df[geo_df['sentiment']=='neutral'].plot(ax=ax, markersize = 20, color = \"green\", marker =\"o\", label = \"Neut\")\n",
    "plt.legend(prop = {'size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for visualization: based on lat & lon and polarity\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_map = gpd.read_file('C:\\Thinkful\\Assignments\\Final_Project_2\\FullYoutubeVideo\\cb_2018_us_county_20m\\cb_2018_us_county_20m.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (50,50))\n",
    "street_map.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now need to overlay the map above with tweet's lat & log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import rtree\n",
    "\n",
    "# bounding box for continental US\n",
    "bbox = [-129.7265625,25.799891182088334,-66.4453125,49.49667452747045]\n",
    "\n",
    "# Rectangles from bbox\n",
    "p1 = Point(bbox[0], bbox[3])\n",
    "p2 = Point(bbox[2], bbox[3])\n",
    "p3 = Point(bbox[2], bbox[1])\n",
    "p4 = Point(bbox[0], bbox[1])\n",
    "\n",
    "# x-coor & y-coor\n",
    "\n",
    "np1 = (p1.coords.xy[0][0], p1.coords.xy[1][0])\n",
    "np2 = (p2.coords.xy[0][0], p2.coords.xy[1][0])\n",
    "np3 = (p3.coords.xy[0][0], p3.coords.xy[1][0])\n",
    "np4 = (p4.coords.xy[0][0], p4.coords.xy[1][0])\n",
    "\n",
    "# define polygon from the points above\n",
    "bb_polygon = Polygon([np1, np2, np3, np4])\n",
    "\n",
    "# make a df\n",
    "df2 = gpd.GeoDataFrame(gpd.GeoSeries(bb_polygon), columns=['geometry'])\n",
    "\n",
    "# overlay\n",
    "intersections2 = gpd.overlay(df2, street_map, how='intersection')\n",
    "#intersections3 = gpd.overlay(geo_df,df2, how='intersection')\n",
    "\n",
    "plt.ion()\n",
    "intersections2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (30,30))\n",
    "intersections2.plot(ax=ax, alpha=0.8)\n",
    "geo_df[geo_df['sentiment']=='positive'].plot(ax=ax, markersize = 100, color = \"blue\", marker =\"o\", label = \"Pos\")\n",
    "geo_df[geo_df['sentiment']=='negative'].plot(ax=ax, markersize = 100, color = \"red\", marker =\"o\", label = \"Neg\")\n",
    "geo_df[geo_df['sentiment']=='neutral'].plot(ax=ax, markersize = 100, color = \"green\", marker =\"o\", label = \"Neut\")\n",
    "plt.savefig(\"img/Sentiment_Donald_Trump.png\", bbox_inches='tight', pad_inches=2)\n",
    "plt.legend(prop = {'size': 30}, loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
